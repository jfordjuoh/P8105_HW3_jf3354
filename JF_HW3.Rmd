---
title: "p8105_hw3_jf3354"
author: Judy Fordjuoh
date: October 15, 2021
output: github_document
---

#Loading all the librarys/setting the themes,color schemes, and the graph output sizes 
```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(patchwork)
library(p8105.datasets)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

#QUESTION 1
```{r}
data("instacart") #looking at the dataset as a whole. 15 columns and 1,384,617 rows
instacart %>%
  count(aisle) %>%
  arrange(desc(n))

summary(instacart)
```
#Answer: In the instacart data there are 15 columns and 1,384,617 rows. Some variables included the aisle, aisle ID, product id, order numbers, user id, and day of the week which only included 6 days. The data is organized by the order. number.

#Answer: There are 134 aisles. The fresh vegetables aisle(n=150609) and fresh fruits aisle (n= 150473) are the aisles where the most items are ordered from, respectively. 

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() 
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
  labs(
    title = "Number of items ordered in each aisle",
    x = "Aisle Name",
    y = "Number of items"
  ) #how to get the aisle products to turn so we can read them? and the title isn't appearing?
```
#PROBLEM: how to get the aisle products to turn so we can read them? and the title isn't appearing? Also how do I make the Question numbers larger and make all the comments smaller?

```{r}
#Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

#Note to self: %in% checks whether or not the object is contained in the other object.  == is a logical operator that checks for identity properties.

instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(ranking = min_rank(desc(n))) %>%  #ranking the n so that those with the least ranking go to the bottom
  filter(ranking < 4) %>% #so we can get only the the top 3 rankings
  arrange(aisle, ranking) %>%
  knitr::kable()

#Answer: In the baking ingredients aisle, Light Brown Sugar (n=499), Pure Baking Soda (n=387), and Cane Sugar (n=336), are the 3 most popular items. In the dog food care aisle, Snack Sticks Chicken & Rice Recipe Dog Treats (n=30), Organix Chicken & Brown Rice Recipe (n=28), and Small Dog Biscuits (n=26), are the 3 most popular items. In the packaged vegetables and fruits aisle, Organic Baby Spinach (n=9784), Organic Raspberries (n=5546), and Organic Blueberries (n=4966), are the 3 most popular items.
```

```{r}
#Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>%
 knitr::kable()
```


#QUESTION 2
```{r} 
#Note to self: You can change the order level of a factor variable to your specified preference using forcats::fct_relevel (visualization pt 2)

#cleaning the data 
brfss <- brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% #include only responses from “Excellent” to “Poor”
  mutate(response = forcats::fct_relevel(response, c("Excellent", "Very good", "Good", "Fair", "Poor"))) #organizing the responses as a factor taking levels ordered from “Excellent” to “Poor”
```

```{r}
#Note to self: n_distinct efficiently count the number of unique values in a set of vector. Lecture:exploratory analysis.

#In 2002, which states were observed at 7 or more locations? What about in 2010?
brfss %>% 
  filter(year %in% c("2002", "2010")) %>% 
  group_by(year, locationabbr) %>% 
  summarise(location = n_distinct(locationdesc)) %>% #counting the number of times the location is listed in locationdesc then I'll filtering to only those who were in 7 or more locations
  filter(location >= 7)

#Answer: In 2002, CT, FL, and NC, were the three states that were observed at 7 locations. MA and NJ were observed at 8 locations while PA was observed at 10 locations. In 2010, CO, PA and SC were observed at 7 locations, OH was observed at 8 locations, NY and MA were observed at 9 locations, WA and NE were observed at 10 locations, CA, MD, and NC were observed in 12 locations, TX were observed in 16 locations, NJ were observed in 19 locations, and FL were observed in 41 locations
```
  
```{r}
#Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state 
brfss2 <- brfss %>% 
  rename(state = locationabbr) %>%
  filter(response == "Excellent") %>%
  group_by(year, state) %>%
  summarize(average_dv = mean(data_value)) %>%
  ggplot(aes(x = year, y = average_dv, color = state)) +
  geom_line() +
  geom_point() + 
  labs(
    title = "Spaghetti plot of the average data value of locations in each state from 2002 to 2010",
    x = "Year",
    y = "Average Data Value") 
```
#PROBLEM:The spaghetti plot isn't printing

```{r}
#Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.
brfss3 <- brfss %>% 
  select(year,data_value,locationabbr,locationdesc,response) %>% 
  filter(year %in% c("2006") & locationabbr == "NY") %>% 
  
  
temp_plot = 
  ggplot(aes(x = locationdesc, y = data_value)) + 
  geom_hex() +
  labs(
    title = "Distribution of data_value for responses among locations in NY State",
    x = "response",
    y = "Data Value"
  )

brfss4 <- brfss %>% 
  select(year,data_value,locationabbr,locationdesc,response) %>% 
  filter(year %in% c("2010") & locationabbr == "NY") %>% 
  filter(response == "Excellent") %>% 


temp_plot = 
  ggplot(aes(x = response, y = data_value)) + 
  geom_hex() +
  labs(
    title = "Temperature plot",
    x = "Minimum daily temperature (C)",
    y = "Maxiumum daily temperature (C)"
  )
  
#COME BACK AND FINISH THIS
```


#QUESTION 3
```{r}
#Describe the resulting dataset (e.g. what variables exist, how many observations, etc).

accel_df = 
  read_csv('accel_data.csv') %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity.",
    values_to = "activity"
  ) %>%
  mutate(day_type = ifelse(day %in% c("Saturday", "Sunday"),"weekend", "weekday"),
         minute = as.integer(minute))

#Answer: This dataset contains 5 weeks of accelerometer data collected from a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF). There are 50400 rows and 6 columns in the accel_df. The variables in this dataframe are week, day_id, day, minute, activity, and the day_type. Day_type is the variable I created which specifies if a day is a weekday or weekend. 
```

